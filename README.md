# Industrial copper modeling
Using Python scripting, Data Preprocessing, EDA, Streamlit

## Introduction

Enhance your proficiency in data analysis and machine learning with our "Industrial Copper Modeling" project. This project addresses the challenges in the copper industry by employing advanced machine learning techniques to provide precise pricing predictions and lead classification for better customer targeting. You'll gain experience in data preprocessing, feature engineering, and web application development using Streamlit, equipping you to solve real-world problems in manufacturing.

## Table of Contents

- [Key Technologies and Skills](#key-technologies-and-skills)
- [Installation](#installation)
- [Usage](#usage)
- [Features](#features)

## Key Technologies and Skills

- Python
- Numpy
- Pandas
- Scikit-Learn
- Matplotlib
- Seaborn
- Pickle
- Streamlit

## Installation

To run this project, install the required packages:

```bash
pip install numpy pandas scikit-learn xgboost matplotlib seaborn streamlit
```

## Usage

To use this project, follow these steps:

1. **Clone the repository:** `git clone https://github.com/barkhavarshney/Industrial-copper-modeling`

2. **Install the required packages:** `pip install -r requirements.txt`

3. **Run the Streamlit app:** `streamlit run App.py`

4. **Access the app in your browser:** Once the Streamlit app is running, access it in your browser at [http://localhost:8501](http://localhost:8501).


## Features

1. **Data Preprocessing**
    - Data Understanding: Gain insights into the dataset's variables and distributions.
    - Handling Null Values: Address missing values in the dataset.
    - Encoding and Data Type Conversion: Prepare categorical features for modeling.
    - Skewness Correction: Mitigate skewness in continuous variables.
    - Outlier Handling: Identify and handle outliers in the data.
    - Wrong Date Handling: Correct inconsistencies in date values.

2. **Exploratory Data Analysis (EDA) and Feature Engineering**
    - Skewness Visualization: Visualize and correct skewness in continuous variables.
    - Outlier Visualization: Identify and rectify outliers using visualizations.
    - Feature Improvement: Enhance dataset quality and efficiency through feature creation.

3. **Classification**
    - Success and Failure Classification: Classify data points based on success and failure.
    - Handling Data Imbalance: Address imbalance in the dataset for classification tasks.
    - Algorithm Assessment: Evaluate various algorithms for classification tasks.
    - Algorithm Selection: Choose the best algorithm for classification based on performance.
    - Hyperparameter Tuning: Fine-tune algorithms for optimal performance.
    - Model Accuracy and Metrics: Evaluate classification model performance using various metrics.
    - Model Persistence: Save trained classification models for future use.

4. **Regression**
    - Algorithm Assessment: Evaluate various algorithms for regression tasks.
    - Algorithm Selection: Choose the best algorithm for regression based on performance.
    - Hyperparameter Tuning: Fine-tune algorithms for optimal performance.
    - Model Accuracy and Metrics: Evaluate regression model performance using various metrics.
    - Model Persistence: Save trained regression models for future use.


## Conclusion

The Industrial Copper Modeling project aims to predict the selling price and status in the industrial copper market using machine learning techniques.

